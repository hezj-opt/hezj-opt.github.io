<!DOCTYPE html><html lang="zh-CN" id="theme-light-mode"><head><!-- hexo injector head_begin start --><link href="/css/hexo-widget-tree.css" rel="stylesheet"/><!-- hexo injector head_begin end --><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><meta name="author" content="核子"><title>hexo配置问题 · 核子的Blog</title><meta name="description" content="记录hexo配置中遇到的各种问题，随缘更新中……


OS：Windows 10
主页类型：gitpage
官方文档：文档 | Hexo




第一个网页
部署到github
配置主题

安装
配置


正文部分

写入正文
编辑文章的分类、标签
插入图片
插入公式
插入TOC目录
插入代码


"><meta name="keywords" content="Blog,博客,Hexo"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="renderer" content="webkit"><link rel="shortcut icon" type="image/x-icon" href="/images/mylogo.webp"><link rel="stylesheet" href="/css/style.css"><link rel="stylesheet" href="/css/blog_basic.css"><link rel="stylesheet" href="/css/font-awesome.min.css"><link rel="stylesheet" href="/css/insight.css"><link rel="stylesheet" href="/css/search.css"><link rel="alternate" type="application/atom+xml" title="ATOM 1.0" href="/atom.xml"><script src="/js/jquery.js"></script><meta name="generator" content="Hexo 6.3.0"></head><body><div class="page-top animated fadeInDown"><div class="nav"><li> <a href="/">首页</a></li><li> <a href="/archives">归档</a></li><li> <a href="/categories">分类</a></li><li> <a href="/tags">标签</a></li><li> <a href="/about">关于</a></li><li> <a href="/links">友链</a></li></div><div class="information"><div class="nav_right_btn"><li><a class="fa fa-chevron-left" onclick="window.history.go(-1)"> </a></li><li><a class="fa fa-search" onclick="openWindow();"></a></li></div><div class="avatar"><img src="/images/mylogo.webp"></div></div></div><div class="sidebar animated fadeInDown"><div class="sidebar-top"><div class="logo-title"><div class="title"><img src="/images/mylogo.webp" style="width:220px;" alt="favicon"><h3 title=""><a href="/">核子的Blog</a></h3><div class="description"><p>A simple blog</p></div></div><ul class="social-links"><li><a target="_blank" rel="noopener" href="https://github.com/hezj-opt"><i class="fa fa-github"></i></a></li><li><a href="mailto:zijun_he@zju.edu.cn"><i class="fa fa-envelope"></i></a></li></ul></div></div><div class="footer"><div class="p"> <span> 全站CC-BY-SA-3.0 </span><i class="fa fa-star"></i><span> 核子</span></div><div class="by_farbox"><span>Powered by </span><a href="https://hexo.io/zh-cn/" target="_blank">Hexo </a><span> & </span><span>Anatolo </span></div><div class="beian"></div></div></div><div class="main"><div class="autopagerize_page_element"><div class="content"><div class="post-page"><div class="post animated fadeInDown"><div class="post-title"><h3><a>hexo配置问题</a></h3></div><div class="post-content"><p><blockquote>
<p>记录hexo配置中遇到的各种问题，随缘更新中……</p>
</blockquote>
<ul>
<li>OS：Windows 10</li>
<li>主页类型：gitpage</li>
<li>官方文档：<a target="_blank" rel="noopener" href="https://hexo.io/zh-cn/docs/">文档 | Hexo</a></li>
</ul>
<div class="toc">
<!-- toc -->
<ul>
<li><a href="#di-yi-ge-wang-ye">第一个网页</a></li>
<li><a href="#bu-shu-dao-github">部署到github</a></li>
<li><a href="#pei-zhi-zhu-ti">配置主题</a>
<ul>
<li><a href="#an-zhuang">安装</a></li>
<li><a href="#pei-zhi">配置</a></li>
</ul>
</li>
<li><a href="#zheng-wen-bu-fen">正文部分</a>
<ul>
<li><a href="#xie-ru-zheng-wen">写入正文</a></li>
<li><a href="#bian-ji-wen-zhang-de-fen-lei-biao-qian">编辑文章的分类、标签</a></li>
<li><a href="#cha-ru-tu-pian">插入图片</a></li>
<li><a href="#cha-ru-gong-shi">插入公式</a></li>
<li><a href="#cha-ru-toc-mu-lu">插入TOC目录</a></li>
<li><a href="#cha-ru-dai-ma">插入代码</a></li>
</ul>
</li>
<li><a href="#about-ye">About页</a></li>
<li><a href="#tag-ye">Tag页</a></li>
</ul>
<!-- tocstop -->
</div>
<h1 tabindex="-1"><span id="di-yi-ge-wang-ye-p">第一个网页 </span></h1>
<p>此部分根据官方文档操作即可完成，故不赘述</p>
<ul>
<li>
<p>安装：<a target="_blank" rel="noopener" href="https://hexo.io/zh-cn/docs/">文档 | Hexo</a></p>
</li>
<li>
<p>建站：<a target="_blank" rel="noopener" href="https://hexo.io/zh-cn/docs/setup">建站 | Hexo</a></p>
</li>
</ul>
<h1 tabindex="-1"><span id="bu-shu-dao-github-p">部署到github </span></h1>
<p>此部分根据官方文档操作即可完成，故不赘述</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://hexo.io/zh-cn/docs/github-pages">在 GitHub Pages 上部署 Hexo | Hexo</a></li>
<li><a target="_blank" rel="noopener" href="https://hexo.io/zh-cn/docs/one-command-deployment">一键部署 | Hexo</a></li>
</ul>
<h1 tabindex="-1"><span id="pei-zhi-zhu-ti-p">配置主题 </span></h1>
<p><a target="_blank" rel="noopener" href="https://hexo.io/themes/">这里面</a>有非常多主题，随便选一个自己喜欢的用就好了。</p>
<p>我选择的主题是Anatolo，这个主题的作者锦心是一位可爱的OIer妹妹（她还不到大一就能自己写theme，而我配置她的主题都磕磕绊绊quq），她的主页：<a target="_blank" rel="noopener" href="https://lhcfl.github.io/">Lhc_fl Home (lhcfl.github.io)</a></p>
<h2 tabindex="-1"><span id="an-zhuang-p">安装 </span></h2>
<p>参考<a target="_blank" rel="noopener" href="https://lhcfl.github.io/Anatolodemo/">Anatolo (lhcfl.github.io)</a></p>
<h2 tabindex="-1"><span id="pei-zhi-p">配置 </span></h2>
<blockquote>
<p>复制<code>_config.example.yml</code>为<code>_config.yml</code>，修改hexo根目录下的 <code>_config.yml</code> ： <code>theme: Anatolo</code></p>
</blockquote>
<p>上面是锦心写的配置方法，但是当时我花了很久时间才理解，具体来说应该是把<code>themes/Anatolo</code>下的<code>_config.example.yml</code>文件复制到<code>themes/Anatolo</code>（一开始我以为是复制到根目录……），然后修改hexo项目<strong>根目录</strong>下的 <code>_config.yml</code> ： <code>theme: Anatolo</code>。</p>
<h1 tabindex="-1"><span id="zheng-wen-bu-fen-p">正文部分 </span></h1>
<h2 tabindex="-1"><span id="xie-ru-zheng-wen-p">写入正文 </span></h2>
<ul>
<li>新建文章 ：用<code>hexo new &lt;title&gt; </code>，可以在<code>_post</code>目录下新建<code>&lt;title&gt;.md</code>文件，之后便可以按照markdown语法开始写作。</li>
</ul>
<h2 tabindex="-1"><span id="bian-ji-wen-zhang-de-fen-lei-biao-qian-p">编辑文章的分类、标签 </span></h2>
<p>参照如下写法即可</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">title: hexo配置问题</span><br><span class="line">date: 2023-01-12 02:45:58</span><br><span class="line">tags: </span><br><span class="line"><span class="bullet">    -</span> 环境配置</span><br><span class="line"><span class="bullet">    -</span> hexo</span><br><span class="line">categories:</span><br><span class="line"><span class="bullet">    -</span> 环境配置</span><br></pre></td></tr></table></figure>
<h2 tabindex="-1"><span id="cha-ru-tu-pian-p">插入图片 </span></h2>
<p>这篇文章十分详细地讲了如何方便地结合Typora插入图片：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/265077468">hexo博客如何插入图片 - 知乎 (zhihu.com)</a></p>
<h2 tabindex="-1"><span id="cha-ru-gong-shi-p">插入公式 </span></h2>
<p>找不到参考的文章了quq</p>
<p>告诫我配置完环境一定要马上整理</p>
<p><strong>警钟长鸣</strong></p>
<h2 tabindex="-1"><span id="cha-ru-toc-mu-lu-p">插入TOC目录 </span></h2>
<p>直接用Typora中的TOC是不能插入目录的！</p>
<p>正确插入方法如下：</p>
<ol>
<li>
<p>安装<a target="_blank" rel="noopener" href="https://github.com/bubkoo/hexo-toc">hexo-toc</a>插件：<code>npm install hexo-toc --save</code></p>
</li>
<li>
<p>参照文档内的方法编辑<code>_config.yml</code></p>
</li>
<li>
<p>在想插入目录的地方写入</p>
<figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&lt;!-- toc --&gt;</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 tabindex="-1"><span id="cha-ru-dai-ma-p">插入代码 </span></h2>
<p>无需插件，正常写入即可。</p>
<p>TODO：学习利用插件对代码块进行优化的方法。</p>
<h1 tabindex="-1"><span id="about-ye-p">About页 </span></h1>
<p>用<code>hexo new page &quot;about&quot;</code>新建“关于”页面，然后正常写入内容即可</p>
<h1 tabindex="-1"><span id="tag-ye-p">Tag页 </span></h1>
<p>用<code>hexo new page &quot;tag&quot;</code>新建标签统计页面即可，无需写入任何内容</p>
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/katex/dist/katex.min.css">
<link rel="stylesheet" href="//cdn.jsdelivr.net/npm/markdown-it-texmath/css/texmath.min.css">
</p><div class="tip">本文采用CC-BY-SA-3.0协议，转载请注明出处<br>作者: 核子</div></div><div class="post-footer"><div class="meta"><div class="info"><i class="fa fa-sun-o"></i><span class="date">2023-01-12</span><a class="tag" href="/categories/环境配置/" title="环境配置">环境配置 </a><i class="fa fa-tag"></i><a class="tag" href="/tags/环境配置/" title="环境配置">环境配置 </a><i class="fa fa-tag"></i><a class="tag" href="/tags/hexo/" title="hexo">hexo </a><span class="leancloud_visitors"></span><span>大约704个字, 2分钟20秒读完</span></div></div></div></div><div class="share"><div class="evernote"><a class="fa fa-bookmark" href="" onclick="javascript:join_favorite()" ref="sidebar"></a></div><div class="weibo"><a class="fa fa-weibo" href="javascript:void((function(s,d,e){try{}catch(e){}var f='http://service.weibo.com/share/share.php?',u=d.location.href,p=['url=',e(u),'&amp;title=',e(d.title),'&amp;appkey=2924220432'].join('');function a(){if(!window.open([f,p].join(''),'mb',['toolbar=0,status=0,resizable=1,width=620,height=450,left=',(s.width-620)/2,',top=',(s.height-450)/2].join('')))u.href=[f,p].join('');};if(/Firefox/.test(navigator.userAgent)){setTimeout(a,0)}else{a()}})(screen,document,encodeURIComponent));"></a></div><div class="twitter"><a class="fa fa-twitter" target="_blank" rel="noopener" href="http://twitter.com/intent/tweet?text=%E5%88%86%E4%BA%AB%E6%96%87%E7%AB%A0%EF%BC%9A%0A%0A%E6%A0%B8%E5%AD%90%E7%9A%84Blog%20%C2%B7%20hexo%E9%85%8D%E7%BD%AE%E9%97%AE%E9%A2%98%0Ahttp://hezj-opt.github.io/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/hexo%E9%85%8D%E7%BD%AE%E9%97%AE%E9%A2%98/%0A"></a></div></div><div class="pagination"><ul class="clearfix"><li class="pre pagbuttons"><a class="btn" role="navigation" href="/Deep-Learning/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-lect4-Self-attention/" title="李宏毅机器学习-lect4-Self attention">上一篇</a></li><li class="next pagbuttons"><a class="btn" role="navigation" href="/Deep-Learning/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E4%B8%BA%E4%BB%80%E4%B9%88%E8%AE%AD%E7%BB%83%E4%BC%9A%E5%A4%B1%E8%B4%A5/" title="李宏毅机器学习-为什么训练会失败">下一篇</a></li></ul></div><script src="/js/visitors.js"></script></div></div></div></div><script src="/js/darkLightToggle.js"></script><script src="/js/jquery-migrate-1.2.1.min.js"></script><script src="/js/jquery.appear.js"></script><script src="/js/add-bookmark.js"></script><script>(function(window){var INSIGHT_CONFIG={TRANSLATION:{POSTS:"文章",PAGES:"页面",CATEGORIES:"分类",TAGS:"标签",UNTITLED:"(无标题)",},CONTENT_URL:"/content.json",};window.INSIGHT_CONFIG=INSIGHT_CONFIG})(window);</script><script src="/js/insight.js" defer></script><div class="searchbox ins-search"><div class="searchbox-container ins-search-container"><div class="searchbox-input-wrapper"><input class="searchbox-input ins-search-input" type="text" placeholder="想要查找什么..."><span class="searchbox-close"><a class="fa fa-times-circle" onclick="closeWindow();"></a></span></div><div class="searchbox-result-wrapper ins-section-wrapper"><div class="ins-section-container"><p>Seraching...</p></div></div></div></div><!-- hexo injector body_end start --><script src="/js/hexo-widget-tree.js"></script><div id="widget-tree">
      <ul>
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/">
          环境配置
        </a>
      <span class="tree-list-count">1</span><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-toc-icon gg-file-add"></i><a class="tree-list-post-link" href="/%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE/hexo%E9%85%8D%E7%BD%AE%E9%97%AE%E9%A2%98/" title="hexo配置问题">hexo配置问题</a><ol class="tree-post-toc"><li class="tree-post-toc-item tree-post-toc-level-1"><a class="tree-post-toc-link"><span class="tree-post-toc-text">第一个网页 </span></a></li><li class="tree-post-toc-item tree-post-toc-level-1"><a class="tree-post-toc-link"><span class="tree-post-toc-text">部署到github </span></a></li><li class="tree-post-toc-item tree-post-toc-level-1"><a class="tree-post-toc-link"><span class="tree-post-toc-text">配置主题 </span></a><ol class="tree-post-toc-child"><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">安装 </span></a></li><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">配置 </span></a></li></ol></li><li class="tree-post-toc-item tree-post-toc-level-1"><a class="tree-post-toc-link"><span class="tree-post-toc-text">正文部分 </span></a><ol class="tree-post-toc-child"><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">写入正文 </span></a></li><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">编辑文章的分类、标签 </span></a></li><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">插入图片 </span></a></li><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">插入公式 </span></a></li><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">插入TOC目录 </span></a></li><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">插入代码 </span></a></li></ol></li><li class="tree-post-toc-item tree-post-toc-level-1"><a class="tree-post-toc-link"><span class="tree-post-toc-text">About页 </span></a></li><li class="tree-post-toc-item tree-post-toc-level-1"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Tag页 </span></a></li></ol></li></ul></li>
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/Deep-Learning/">
          Deep Learning
        </a>
      <span class="tree-list-count">7</span><ul class="tree-list-children">
      <li class="tree-list-item">
        <i class="toggle-post-icon gg-folder-add"></i>
        <a class="tree-list-link" href="/categories/Deep-Learning/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/">
          李宏毅机器学习
        </a>
      <span class="tree-list-count">6</span><ul class="tree-list-children"><li class="tree-list-item"><i class="toggle-toc-icon gg-file-add"></i><a class="tree-list-post-link" href="/Deep-Learning/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-hw3-CNN-%E6%80%BB%E7%BB%93/" title="李宏毅机器学习-hw3-CNN-总结">李宏毅机器学习-hw3-CNN-总结</a><ol class="tree-post-toc"><li class="tree-post-toc-item tree-post-toc-level-1"><a class="tree-post-toc-link"><span class="tree-post-toc-text">任务介绍 </span></a></li><li class="tree-post-toc-item tree-post-toc-level-1"><a class="tree-post-toc-link"><span class="tree-post-toc-text">训练结果 </span></a></li><li class="tree-post-toc-item tree-post-toc-level-1"><a class="tree-post-toc-link"><span class="tree-post-toc-text">训练方法 </span></a><ol class="tree-post-toc-child"><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Data augmentation </span></a></li><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">模型设计 </span></a></li><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Loss function的选择与调参 </span></a></li><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Learning rate调整方案 </span></a></li><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Test time augmentation </span></a></li></ol></li><li class="tree-post-toc-item tree-post-toc-level-1"><a class="tree-post-toc-link"><span class="tree-post-toc-text">进一步提升的可能 </span></a><ol class="tree-post-toc-child"><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">数据增强可能可以尝试mix up </span></a></li><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">模型设计可能可以继续尝试 </span></a></li><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Learning rate调整方案有待提升 </span></a></li><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Cross Validation + Ensemble </span></a></li></ol></li><li class="tree-post-toc-item tree-post-toc-level-1"><a class="tree-post-toc-link"><span class="tree-post-toc-text">其它值得记录的东西 </span></a><ol class="tree-post-toc-child"><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">autodl tensorboard使用 </span></a></li><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">layer的梯度变化 </span></a></li></ol></li></ol></li><li class="tree-list-item"><i class="toggle-toc-icon gg-file-add"></i><a class="tree-list-post-link" href="/Deep-Learning/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-lect3-CNN/" title="李宏毅机器学习-lect3-CNN">李宏毅机器学习-lect3-CNN</a><ol class="tree-post-toc"><li class="tree-post-toc-item tree-post-toc-level-1"><a class="tree-post-toc-link"><span class="tree-post-toc-text">CNN 的想法 </span></a></li><li class="tree-post-toc-item tree-post-toc-level-1"><a class="tree-post-toc-link"><span class="tree-post-toc-text">卷积层（Convolutional layers） </span></a><ol class="tree-post-toc-child"><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">卷积核 </span></a></li><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">步长 （Stride） </span></a></li><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">填充 （Padding） </span></a></li><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">参数共享（Parameter Sharing） </span></a></li><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">卷积层的运行过程 </span></a></li><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">卷积层的两种理解方式 </span></a></li></ol></li><li class="tree-post-toc-item tree-post-toc-level-1"><a class="tree-post-toc-link"><span class="tree-post-toc-text">池化层（Pooling layers） </span></a></li><li class="tree-post-toc-item tree-post-toc-level-1"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Flatten layers </span></a></li><li class="tree-post-toc-item tree-post-toc-level-1"><a class="tree-post-toc-link"><span class="tree-post-toc-text">CNN 的缺点 </span></a></li></ol></li><li class="tree-list-item"><i class="toggle-toc-icon gg-file-add"></i><a class="tree-list-post-link" href="/Deep-Learning/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-lect4-Self-attention/" title="李宏毅机器学习-lect4-Self attention">李宏毅机器学习-lect4-Self attention</a><ol class="tree-post-toc"><li class="tree-post-toc-item tree-post-toc-level-1"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Self attention 解决什么问题 </span></a><ol class="tree-post-toc-child"><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">FC(Fully Connected)有什么不足 </span></a></li></ol></li><li class="tree-post-toc-item tree-post-toc-level-1"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Self attention 的架构 </span></a></li><li class="tree-post-toc-item tree-post-toc-level-1"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Self attention 的基本计算过程 </span></a><ol class="tree-post-toc-child"><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">求attention score </span></a></li><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">求解Self attention层输出的向量 </span></a></li><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">矩阵视角下的计算过程 </span></a></li></ol></li><li class="tree-post-toc-item tree-post-toc-level-1"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Self attention的优化 </span></a><ol class="tree-post-toc-child"><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Multi-head Self attention </span></a></li><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Positional Encoding </span></a></li></ol></li><li class="tree-post-toc-item tree-post-toc-level-1"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Self attention 和其他网络对比 </span></a><ol class="tree-post-toc-child"><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">CNN </span></a></li><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">RNN </span></a></li><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">GNN </span></a></li></ol></li></ol></li><li class="tree-list-item"><i class="toggle-toc-icon gg-file-add"></i><a class="tree-list-post-link" href="/Deep-Learning/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-lect5-Transformer/" title="李宏毅机器学习-lect5-Transformer">李宏毅机器学习-lect5-Transformer</a><ol class="tree-post-toc"><li class="tree-post-toc-item tree-post-toc-level-1"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Transformer是什么 </span></a></li><li class="tree-post-toc-item tree-post-toc-level-1"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Transformer的应用 </span></a></li><li class="tree-post-toc-item tree-post-toc-level-1"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Transformer的架构 </span></a><ol class="tree-post-toc-child"><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Encoder </span></a></li><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Decoder </span></a></li><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Autoregressive Transformer </span></a><ol class="tree-post-toc-child"><li class="tree-post-toc-item tree-post-toc-level-3"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Masked Self-attention </span></a></li><li class="tree-post-toc-item tree-post-toc-level-3"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Cross attention </span></a></li></ol></li><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Non autoregressive Transformer(NAT) </span></a></li></ol></li><li class="tree-post-toc-item tree-post-toc-level-1"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Transformer的训练 </span></a><ol class="tree-post-toc-child"><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">loss的来源 </span></a></li><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">训练的一些tips </span></a><ol class="tree-post-toc-child"><li class="tree-post-toc-item tree-post-toc-level-3"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Teacher Forcing </span></a></li><li class="tree-post-toc-item tree-post-toc-level-3"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Copy Mechanism </span></a></li><li class="tree-post-toc-item tree-post-toc-level-3"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Guided Attention </span></a></li><li class="tree-post-toc-item tree-post-toc-level-3"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Beam Search </span></a></li><li class="tree-post-toc-item tree-post-toc-level-3"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Exposure bias </span></a></li></ol></li></ol></li></ol></li><li class="tree-list-item"><i class="toggle-toc-icon gg-file-add"></i><a class="tree-list-post-link" href="/Deep-Learning/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-%E4%B8%BA%E4%BB%80%E4%B9%88%E8%AE%AD%E7%BB%83%E4%BC%9A%E5%A4%B1%E8%B4%A5/" title="李宏毅机器学习-为什么训练会失败">李宏毅机器学习-为什么训练会失败</a><ol class="tree-post-toc"><li class="tree-post-toc-item tree-post-toc-level-1"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Training loss很高 </span></a><ol class="tree-post-toc-child"><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">这时发生了什么 </span></a></li><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">训练方法 </span></a><ol class="tree-post-toc-child"><li class="tree-post-toc-item tree-post-toc-level-3"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Batch </span></a><ol class="tree-post-toc-child"><li class="tree-post-toc-item tree-post-toc-level-4"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Batch对训练效率影响 </span></a></li><li class="tree-post-toc-item tree-post-toc-level-4"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Batch对训练效果影响 </span></a></li></ol></li><li class="tree-post-toc-item tree-post-toc-level-3"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Momentum </span></a></li><li class="tree-post-toc-item tree-post-toc-level-3"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Learning rate </span></a></li><li class="tree-post-toc-item tree-post-toc-level-3"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Loss function </span></a></li></ol></li></ol></li><li class="tree-post-toc-item tree-post-toc-level-1"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Training data的loss很小 </span></a><ol class="tree-post-toc-child"><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">过拟合 </span></a><ol class="tree-post-toc-child"><li class="tree-post-toc-item tree-post-toc-level-3"><a class="tree-post-toc-link"><span class="tree-post-toc-text">调整模型复杂度 </span></a></li><li class="tree-post-toc-item tree-post-toc-level-3"><a class="tree-post-toc-link"><span class="tree-post-toc-text">添加更多数据 </span></a></li></ol></li><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Mismatch </span></a></li></ol></li></ol></li><li class="tree-list-item"><i class="toggle-toc-icon gg-file-add"></i><a class="tree-list-post-link" href="/Deep-Learning/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9D%8E%E5%AE%8F%E6%AF%85%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0-lect6-GAN/" title="李宏毅机器学习-lect6-GAN">李宏毅机器学习-lect6-GAN</a><ol class="tree-post-toc"><li class="tree-post-toc-item tree-post-toc-level-1"><a class="tree-post-toc-link"><span class="tree-post-toc-text">GAN的基本思想 </span></a><ol class="tree-post-toc-child"><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">生成器 </span></a></li><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">“对抗”的含义 </span></a></li><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">训练过程概述 </span></a></li></ol></li><li class="tree-post-toc-item tree-post-toc-level-1"><a class="tree-post-toc-link"><span class="tree-post-toc-text">GAN的理论 </span></a><ol class="tree-post-toc-child"><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">目标函数 </span></a><ol class="tree-post-toc-child"><li class="tree-post-toc-item tree-post-toc-level-3"><a class="tree-post-toc-link"><span class="tree-post-toc-text">JS divergence的缺陷 </span></a></li><li class="tree-post-toc-item tree-post-toc-level-3"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Wasserstein distance </span></a></li></ol></li><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">评价生成器 </span></a><ol class="tree-post-toc-child"><li class="tree-post-toc-item tree-post-toc-level-3"><a class="tree-post-toc-link"><span class="tree-post-toc-text">评价指标 </span></a><ol class="tree-post-toc-child"><li class="tree-post-toc-item tree-post-toc-level-4"><a class="tree-post-toc-link"><span class="tree-post-toc-text">图像质量 </span></a></li><li class="tree-post-toc-item tree-post-toc-level-4"><a class="tree-post-toc-link"><span class="tree-post-toc-text">图像多样性 </span></a></li></ol></li><li class="tree-post-toc-item tree-post-toc-level-3"><a class="tree-post-toc-link"><span class="tree-post-toc-text">评价函数 </span></a><ol class="tree-post-toc-child"><li class="tree-post-toc-item tree-post-toc-level-4"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Inception score </span></a></li><li class="tree-post-toc-item tree-post-toc-level-4"><a class="tree-post-toc-link"><span class="tree-post-toc-text">FID </span></a></li></ol></li></ol></li></ol></li><li class="tree-post-toc-item tree-post-toc-level-1"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Conditional GAN（条件式生成） </span></a><ol class="tree-post-toc-child"><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Conditional-GAN+监督学习 </span></a></li></ol></li><li class="tree-post-toc-item tree-post-toc-level-1"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Cycle-GAN </span></a><ol class="tree-post-toc-child"><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">为什么需要Cycle-GAN </span></a></li><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Cycle-GAN的结构 </span></a></li><li class="tree-post-toc-item tree-post-toc-level-2"><a class="tree-post-toc-link"><span class="tree-post-toc-text">Cycle-GAN的其他应用 </span></a></li></ol></li></ol></li></ul></li></ul></li></ul>
        <div id="widget-tree-button">
          <i class="gg-chevron-right"></i>
        </div>
      </div><!-- hexo injector body_end end --></body></html>